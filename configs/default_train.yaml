defaults:
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .

logger:
  level: INFO # look at loguru.logger levels to manage output messages

git: # prevent training with uncommited changes
  check_uncommited: False

wandb:
  use: True
  project: "nerf_playground"
  log_each: 50

dataset:
  path: ???
  image_size: 400
  bg_color: 255 # white background color
  test_each: 25 # step in array of test_images

dataloader:
  train:
    shuffle: True
    num_workers: 4
    pin_memory: True
    batch_size: 1024 # number of rays penetrating the model
    persistent_workers: True # uncomment if num_workers > 0

  val:
    shuffle: False
    num_workers: 4
    pin_memory: True
    batch_size: 8000 # number of rays penetrating the model
    persistent_workers: True # uncomment if num_workers > 0

model:
  use_fine_mlp: True

  encoding:
    use: True
    num_freqs_coords: 10
    num_freqs_viewdir: 4

  mlp:
    base_layer_num: 8
    base_features_size: 256
    skip_connection_layers: "4"

  interval_sampler:
    near_bound: 2.0 # integral bound, section 4 formula 1
    far_bound: 6.0 # integral bound, section 4 formula 1
    perturb: False # whether to add random offset to interval for sampling points along ray
    lindisp: False # sampling linearly in disparity rather than depth, using in LLFF dataset
    num_samples_coarse: 64

  hierarchical_sampler:
    num_fine_samples: 128
    perturb: False

  volume_renderer:
    train_radiance_field_noise_std: 0.0
    val_radiance_field_noise_std: 0.0
    white_background: True # will shift points with low accuracy to the 1(white) pixel value
    attenuation_threshold: 1e-3

training:
  exp_folder: "experiments"
  seed: 2023
  device: "cuda"
  num_iterations: 500_000
  eval_each: 5_000

  loss:
    type: "MSELoss"

  optimizer:
    type: "Adam"
    args:
      lr: 5e-4

  scheduler:
    type: "LambdaLR"
    gamma: 0.1

defaults:
  # custom defaults
  - dataset: blender_combined
  # hydra staff
  - _self_
  - override hydra/hydra_logging: disabled
  - override hydra/job_logging: disabled

hydra:
  output_subdir: null
  run:
    dir: .
logger:
  # look at loguru.logger levels to manage output messages
  level: INFO
git:
  # prevent training with uncommited changes or not pushed commits
  consistency: False
wandb:
  use: True
  project: "nerf-pytorch"
  log_each: 50
  save_val_ckpt: False

dataloader:
  train:
    shuffle: True
    num_workers: 4
    pin_memory: True
    # number of rays piercing the model
    batch_size: 1024
    # Internet suggests to uncomment if num_workers > 0
    persistent_workers: True
  val:
    shuffle: False
    num_workers: 4
    pin_memory: True
    batch_size: 6000
    persistent_workers: True

model:
  encoding:
    use: True
    num_freqs_coords: 10
    num_freqs_viewdir: 4
  mlp:
    use_viewdir: True
    base_layer_num: 8
    base_features_size: 256
    skip_connection_layers: "4"
  interval_sampler:
    # lower ray's bound (in abs coordinates), m
    near_bound: 2.0
    # higher ray's bound (in abs coordinates), m
    far_bound: 6.0
    # whether to add random offset to interval for sampling points along ray 
    perturb: False
    # sampling linearly in disparity rather than depth, using in LLFF dataset (NDC space)
    lindisp: False
    num_samples: 64
  hierarchical_sampler:
    use: True
    num_samples: 128
    perturb: False
  volume_renderer:
    train_radiance_field_noise_std: 0.0
    val_radiance_field_noise_std: 0.0
    # will shift points with low accuracy to the white pixel value (background)
    white_background: True
    attenuation_threshold: 1e-3

training:
  exp_folder: "experiments"
  seed: 2023
  device: "cuda"
  num_iterations: 300_000
  eval_each: 5_000
  loss:
    _target_: torch.nn.modules.loss.MSELoss
  optimizer:
    type: "Adam"
    args:
      lr: 5e-4
  scheduler:
    type: "LambdaLR"
    gamma: 0.1
